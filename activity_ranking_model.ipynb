{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Family Activity Ranking Model\n",
    "\n",
    "This notebook implements a machine learning model that merges group members' ages and power levels (overall ability) to rank activities suitable for the entire group.\n",
    "\n",
    "## Features:\n",
    "- Age-based activity filtering\n",
    "- Power/ability-based scoring\n",
    "- Group compatibility analysis\n",
    "- Multi-factor ranking algorithm\n",
    "\n",
    "## Google Colab Compatible\n",
    "Upload your `dataset/dataset empty -open space-.csv` file when running on Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Methodology\n\nWe build on foundational methods in information retrieval and modern semantic search to create a robust activity ranking system:\n\n### Core Technologies:\n\n1. **BM25 (Best Matching 25)**: Provides strong keyword-based baselines for activity search and ranking. BM25 is a probabilistic ranking function that considers term frequency, inverse document frequency, and document length normalization [Robertson & Zaragoza, 2009].\n\n2. **Sentence-BERT**: Enables dense embeddings for semantic similarity, allowing us to understand the meaning and context of activities beyond simple keyword matching [Reimers & Gurevych, 2019].\n\n3. **FAISS (Facebook AI Similarity Search)**: Supports efficient approximate nearest neighbor search at scale, enabling fast similarity computations across large activity databases [Johnson et al., 2017].\n\n4. **MMR (Maximal Marginal Relevance)**: Introduces diversity-aware ranking to ensure recommended activities are both relevant and diverse, preventing redundant suggestions [Carbonell & Goldstein, 1998].\n\n### Data Sources:\n\nFor content, we collect activity data from trusted family and education resources:\n- **Raising Children Network**: Evidence-based parenting information\n- **Active for Life**: Physical literacy and child development activities\n- **Oxford Owl**: Educational activities and learning resources\n- **Positive Action**: Social-emotional learning activities\n- **Escape Room Geeks**: Problem-solving and group activities\n- Additional curated educational and recreational resources\n\n### References:\n- Robertson, S., & Zaragoza, H. (2009). The Probabilistic Relevance Framework: BM25 and Beyond. *Foundations and Trends in Information Retrieval*, 3(4), 333-389.\n- Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. *EMNLP 2019*.\n- Johnson, J., Douze, M., & Jégou, H. (2017). Billion-scale similarity search with GPUs. *arXiv preprint arXiv:1702.08734*.\n- Carbonell, J., & Goldstein, J. (1998). The use of MMR, diversity-based reranking for reordering documents and producing summaries. *SIGIR 1998*.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom typing import List, Dict, Tuple\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Information Retrieval and Semantic Search Libraries\ntry:\n    from rank_bm25 import BM25Okapi\n    print(\"✓ BM25 available\")\nexcept ImportError:\n    print(\"⚠ BM25 not installed. Install with: pip install rank-bm25\")\n    BM25Okapi = None\n\ntry:\n    from sentence_transformers import SentenceTransformer\n    print(\"✓ Sentence-BERT available\")\nexcept ImportError:\n    print(\"⚠ Sentence-BERT not installed. Install with: pip install sentence-transformers\")\n    SentenceTransformer = None\n\ntry:\n    import faiss\n    print(\"✓ FAISS available\")\nexcept ImportError:\n    print(\"⚠ FAISS not installed. Install with: pip install faiss-cpu\")\n    faiss = None\n\n# Set style for visualizations\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)\n\nprint(\"✓ Core libraries imported successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Group Member Structure\n",
    "\n",
    "Each member has:\n",
    "- **age**: Member's age in years\n",
    "- **overall_ability**: Power level (1-10 scale) representing physical and cognitive capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupMember:\n",
    "    \"\"\"Represents a family member with age and ability attributes\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, age: int, overall_ability: float, \n",
    "                 interests: List[str] = None, special_needs: List[str] = None):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "        self.overall_ability = overall_ability  # 1-10 scale\n",
    "        self.interests = interests or []\n",
    "        self.special_needs = special_needs or []\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.name} (Age: {self.age}, Ability: {self.overall_ability})\"\n",
    "\n",
    "\n",
    "class FamilyGroup:\n",
    "    \"\"\"Manages a group of family members\"\"\"\n",
    "    \n",
    "    def __init__(self, members: List[GroupMember] = None):\n",
    "        self.members = members or []\n",
    "    \n",
    "    def add_member(self, member: GroupMember):\n",
    "        self.members.append(member)\n",
    "    \n",
    "    def get_age_range(self) -> Tuple[int, int]:\n",
    "        \"\"\"Returns (min_age, max_age) of the group\"\"\"\n",
    "        if not self.members:\n",
    "            return (0, 0)\n",
    "        ages = [m.age for m in self.members]\n",
    "        return (min(ages), max(ages))\n",
    "    \n",
    "    def get_avg_ability(self) -> float:\n",
    "        \"\"\"Returns average overall_ability of the group\"\"\"\n",
    "        if not self.members:\n",
    "            return 0.0\n",
    "        return np.mean([m.overall_ability for m in self.members])\n",
    "    \n",
    "    def get_ability_range(self) -> Tuple[float, float]:\n",
    "        \"\"\"Returns (min_ability, max_ability) of the group\"\"\"\n",
    "        if not self.members:\n",
    "            return (0.0, 0.0)\n",
    "        abilities = [m.overall_ability for m in self.members]\n",
    "        return (min(abilities), max(abilities))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"FamilyGroup({len(self.members)} members)\"\n",
    "\n",
    "\n",
    "print(\"✓ Group member classes defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sample Family Group\n",
    "\n",
    "Define your family members here with their ages and ability levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example family group\n",
    "sample_group = FamilyGroup([\n",
    "    GroupMember(\"Emma\", age=10, overall_ability=7.0, \n",
    "                interests=[\"Arts & Crafts\", \"Reading\", \"Nature\"]),\n",
    "    GroupMember(\"Liam\", age=6, overall_ability=5.0, \n",
    "                interests=[\"Sports\", \"Building\", \"Outdoors\"]),\n",
    "    GroupMember(\"Sophia\", age=13, overall_ability=8.5, \n",
    "                interests=[\"Music\", \"Dance\", \"Art\"]),\n",
    "    GroupMember(\"Dad\", age=42, overall_ability=6.0, \n",
    "                interests=[\"Sports\", \"Hiking\", \"Cooking\"]),\n",
    "])\n",
    "\n",
    "print(\"Family Group Summary:\")\n",
    "print(\"=\" * 50)\n",
    "for member in sample_group.members:\n",
    "    print(f\"  {member}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Age Range: {sample_group.get_age_range()[0]}-{sample_group.get_age_range()[1]} years\")\n",
    "print(f\"Average Ability: {sample_group.get_avg_ability():.2f}/10\")\n",
    "print(f\"Ability Range: {sample_group.get_ability_range()[0]}-{sample_group.get_ability_range()[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Activity Dataset\n",
    "\n",
    "### For Google Colab:\n",
    "Upload your CSV file using the code below, or mount Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "source": "# Easy Installation: Use the requirements.txt file\n# !pip install -r requirements.txt\n\n# OR install packages individually:\n# !pip install rank-bm25 sentence-transformers faiss-cpu\n\n# Note: Use faiss-cpu for maximum compatibility (works on all platforms)\n# Only use faiss-gpu if you have CUDA-enabled GPU and NVIDIA drivers installed\n# !pip install faiss-gpu  # Only if you have CUDA support\n\nprint(\"\"\"\nRequired Packages:\n==================\n\nQuick Install (Recommended):\n   pip install -r requirements.txt\n\nThis will install:\n\n1. rank-bm25: BM25 keyword-based ranking\n   - Install: pip install rank-bm25\n   - Reference: Robertson & Zaragoza (2009)\n\n2. sentence-transformers: Sentence-BERT embeddings\n   - Install: pip install sentence-transformers\n   - Reference: Reimers & Gurevych (2019)\n   - Models will download automatically on first use (~90MB for MiniLM)\n\n3. faiss-cpu: Efficient similarity search (CPU version - works on all platforms)\n   - Install: pip install faiss-cpu\n   - Reference: Johnson et al. (2017)\n   - For GPU: pip install faiss-gpu (requires CUDA - not available on all systems)\n\nCore libraries (already included):\n- pandas, numpy, matplotlib, seaborn\n\nNote: The system will work without these packages but will use fallback methods.\nThe hybrid ranker will automatically detect and use available components.\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Installation Instructions\n\nTo use the hybrid ranking system with all features, install these packages:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Compare different ranking approaches\ntest_query = \"fun outdoor games for children\"\n\nprint(\"=\" * 80)\nprint(f\"Comparing Ranking Methods for Query: '{test_query}'\")\nprint(\"=\" * 80)\n\n# BM25 only (keyword-based)\nresults_bm25 = hybrid_ranker.search(test_query, top_k=10, bm25_weight=1.0, semantic_weight=0.0, use_mmr=False)\nprint(\"\\n1. BM25 (Keyword-Based) - Top 5:\")\nprint(\"-\" * 80)\nprint(results_bm25[['rank', 'title', 'bm25_score']].head(5).to_string(index=False))\n\n# Semantic only (meaning-based)\nresults_semantic = hybrid_ranker.search(test_query, top_k=10, bm25_weight=0.0, semantic_weight=1.0, use_mmr=False)\nprint(\"\\n2. Semantic (Meaning-Based) - Top 5:\")\nprint(\"-\" * 80)\nprint(results_semantic[['rank', 'title', 'semantic_score']].head(5).to_string(index=False))\n\n# Hybrid (combined)\nresults_hybrid = hybrid_ranker.search(test_query, top_k=10, bm25_weight=0.3, semantic_weight=0.7, use_mmr=False)\nprint(\"\\n3. Hybrid (BM25 30% + Semantic 70%) - Top 5:\")\nprint(\"-\" * 80)\nprint(results_hybrid[['rank', 'title', 'hybrid_score', 'bm25_score', 'semantic_score']].head(5).to_string(index=False))\n\n# Hybrid + MMR (diversity-aware)\nresults_mmr = hybrid_ranker.search(test_query, top_k=10, bm25_weight=0.3, semantic_weight=0.7, use_mmr=True)\nprint(\"\\n4. Hybrid + MMR (Diversity-Aware) - Top 5:\")\nprint(\"-\" * 80)\nprint(results_mmr[['rank', 'title', 'hybrid_score']].head(5).to_string(index=False))\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Key Observations:\")\nprint(\"=\" * 80)\nprint(\"• BM25: Excels at exact keyword matching (e.g., 'outdoor', 'games')\")\nprint(\"• Semantic: Captures meaning and context (e.g., finds 'play' activities even without 'games')\")\nprint(\"• Hybrid: Balances keyword precision with semantic understanding\")\nprint(\"• MMR: Adds diversity to prevent redundant similar activities\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Comparing Ranking Methods\n\nCompare BM25 (keyword), Semantic (meaning-based), and Hybrid (combined) approaches.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize hybrid ranking system\nhybrid_ranker = HybridActivityRanker(activities_df)\n\n# Example 1: Keyword-based search\nprint(\"=\" * 80)\nprint(\"EXAMPLE 1: Keyword Search - 'outdoor sports'\")\nprint(\"=\" * 80)\nresults1 = hybrid_ranker.search(\"outdoor sports\", top_k=10)\nprint(results1[['rank', 'title', 'hybrid_score', 'bm25_score', 'semantic_score', \n                'age_min', 'age_max']].to_string(index=False))\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"EXAMPLE 2: Semantic Search - 'creative activities for kids'\")\nprint(\"=\" * 80)\nresults2 = hybrid_ranker.search(\"creative activities for kids\", top_k=10)\nprint(results2[['rank', 'title', 'hybrid_score', 'bm25_score', 'semantic_score',\n                'age_min', 'age_max']].to_string(index=False))\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"EXAMPLE 3: Group-based Search (using sample family)\")\nprint(\"=\" * 80)\nresults3 = hybrid_ranker.search_by_group(sample_group, top_k=10)\nprint(results3[['rank', 'title', 'hybrid_score', 'age_min', 'age_max', 'duration_mins']].to_string(index=False))\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"EXAMPLE 4: Custom Query for Group - 'educational STEM activities'\")\nprint(\"=\" * 80)\nresults4 = hybrid_ranker.search_by_group(sample_group, query=\"educational STEM activities\", top_k=10)\nprint(results4[['rank', 'title', 'hybrid_score', 'age_min', 'age_max']].to_string(index=False))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Hybrid Ranking System Demo\n\nDemonstrate the hybrid ranking system combining BM25, Sentence-BERT, FAISS, and MMR.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class HybridActivityRanker:\n    \"\"\"\n    Hybrid ranking system combining BM25, Sentence-BERT, FAISS, and MMR.\n    Provides state-of-the-art activity search and ranking with diversity awareness.\n    \"\"\"\n    \n    def __init__(self, activities_df: pd.DataFrame):\n        \"\"\"\n        Initialize hybrid ranker with activity data.\n        \n        Args:\n            activities_df: DataFrame containing activity information\n        \"\"\"\n        self.activities_df = activities_df\n        \n        # Prepare text representations of activities\n        self.activity_texts = self._prepare_activity_texts()\n        \n        # Initialize IR components\n        print(\"\\nInitializing hybrid ranking system...\")\n        print(\"-\" * 50)\n        \n        self.bm25_ranker = BM25Ranker(self.activity_texts)\n        self.semantic_embedder = SemanticEmbedder()\n        self.faiss_index = None\n        self.mmr_ranker = MMRRanker(lambda_param=0.6)  # Slightly favor relevance\n        \n        # Build semantic index\n        if self.semantic_embedder.model is not None:\n            self.semantic_embedder.build_index(self.activity_texts)\n            \n            # Build FAISS index\n            if faiss is not None:\n                embedding_dim = self.semantic_embedder.embeddings.shape[1]\n                self.faiss_index = FAISSIndex(embedding_dim)\n                self.faiss_index.add_embeddings(self.semantic_embedder.embeddings)\n        \n        print(\"-\" * 50)\n        print(\"✓ Hybrid ranking system ready\\n\")\n    \n    def _prepare_activity_texts(self) -> List[str]:\n        \"\"\"\n        Prepare text representations of activities for indexing.\n        Combines title, description, tags, and metadata.\n        \"\"\"\n        texts = []\n        for _, row in self.activities_df.iterrows():\n            # Combine relevant fields\n            parts = [\n                str(row.get('title', '')),\n                str(row.get('description', '')),\n                ' '.join(str(tag) for tag in row.get('tags', [])),\n                f\"age {row.get('age_min', '')} to {row.get('age_max', '')}\",\n                str(row.get('indoor_outdoor', '')),\n                str(row.get('category', ''))\n            ]\n            text = ' '.join(part for part in parts if part)\n            texts.append(text)\n        \n        return texts\n    \n    def search(\n        self,\n        query: str,\n        top_k: int = 20,\n        bm25_weight: float = 0.3,\n        semantic_weight: float = 0.7,\n        use_mmr: bool = True,\n        mmr_lambda: float = 0.6\n    ) -> pd.DataFrame:\n        \"\"\"\n        Search activities using hybrid ranking.\n        \n        Args:\n            query: Search query string\n            top_k: Number of results to return\n            bm25_weight: Weight for BM25 scores (keyword matching)\n            semantic_weight: Weight for semantic similarity scores\n            use_mmr: Apply MMR for diversity-aware re-ranking\n            mmr_lambda: MMR lambda parameter (relevance vs diversity trade-off)\n            \n        Returns:\n            DataFrame with ranked activities and scores\n        \"\"\"\n        n_activities = len(self.activities_df)\n        \n        # Get BM25 scores\n        bm25_scores = self.bm25_ranker.get_scores(query)\n        \n        # Get semantic similarity scores\n        semantic_scores = self.semantic_embedder.similarity(query)\n        \n        # Normalize scores to [0, 1]\n        def normalize(scores):\n            if scores.max() > scores.min():\n                return (scores - scores.min()) / (scores.max() - scores.min())\n            return scores\n        \n        bm25_scores_norm = normalize(bm25_scores)\n        semantic_scores_norm = normalize(semantic_scores)\n        \n        # Combine scores\n        hybrid_scores = (\n            bm25_weight * bm25_scores_norm + \n            semantic_weight * semantic_scores_norm\n        )\n        \n        # Get initial ranking\n        initial_ranking = np.argsort(hybrid_scores)[::-1]\n        \n        # Apply MMR for diversity if requested\n        if use_mmr and self.semantic_embedder.embeddings is not None:\n            query_embedding = self.semantic_embedder.encode([query])[0]\n            \n            # Re-rank using MMR\n            final_ranking = self.mmr_ranker.rerank(\n                query_embedding,\n                self.semantic_embedder.embeddings,\n                initial_ranking.tolist(),\n                hybrid_scores,\n                k=top_k,\n                lambda_param=mmr_lambda\n            )\n        else:\n            final_ranking = initial_ranking[:top_k].tolist()\n        \n        # Prepare results\n        results = self.activities_df.iloc[final_ranking].copy()\n        results['hybrid_score'] = hybrid_scores[final_ranking]\n        results['bm25_score'] = bm25_scores_norm[final_ranking]\n        results['semantic_score'] = semantic_scores_norm[final_ranking]\n        results['rank'] = range(1, len(results) + 1)\n        \n        return results\n    \n    def search_by_group(\n        self,\n        group: 'FamilyGroup',\n        query: str = None,\n        top_k: int = 20,\n        use_mmr: bool = True\n    ) -> pd.DataFrame:\n        \"\"\"\n        Search activities suitable for a family group with optional query.\n        Combines hybrid search with age/ability filtering.\n        \n        Args:\n            group: FamilyGroup object\n            query: Optional search query (e.g., \"outdoor sports\")\n            top_k: Number of results to return\n            use_mmr: Apply MMR for diversity\n            \n        Returns:\n            DataFrame with ranked activities\n        \"\"\"\n        # Build query from group characteristics if not provided\n        if query is None:\n            age_min, age_max = group.get_age_range()\n            avg_ability = group.get_avg_ability()\n            \n            query = f\"activities for ages {age_min} to {age_max}\"\n            \n            # Add interests\n            all_interests = []\n            for member in group.members:\n                all_interests.extend(member.interests)\n            if all_interests:\n                unique_interests = list(set(all_interests))[:3]\n                query += f\" {' '.join(unique_interests)}\"\n        \n        # Search\n        results = self.search(query, top_k=top_k * 2, use_mmr=use_mmr)\n        \n        # Filter by age appropriateness\n        age_min, age_max = group.get_age_range()\n        \n        # Keep activities where there's some age overlap\n        def has_age_overlap(row):\n            return not (row['age_max'] < age_min or row['age_min'] > age_max)\n        \n        results = results[results.apply(has_age_overlap, axis=1)]\n        \n        return results.head(top_k)\n\n\nprint(\"✓ HybridActivityRanker class defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class MMRRanker:\n    \"\"\"\n    Maximal Marginal Relevance (MMR) for diversity-aware ranking.\n    Balances relevance to query with diversity among results to avoid redundancy.\n    \"\"\"\n    \n    def __init__(self, lambda_param: float = 0.5):\n        \"\"\"\n        Initialize MMR ranker.\n        \n        Args:\n            lambda_param: Trade-off between relevance and diversity (0-1)\n                         1.0 = pure relevance, 0.0 = pure diversity\n                         Default: 0.5 (balanced)\n        \"\"\"\n        self.lambda_param = lambda_param\n    \n    def compute_mmr(\n        self,\n        query_embedding: np.ndarray,\n        doc_embeddings: np.ndarray,\n        relevance_scores: np.ndarray = None,\n        k: int = 10,\n        lambda_param: float = None\n    ) -> List[int]:\n        \"\"\"\n        Compute MMR ranking for documents.\n        \n        Args:\n            query_embedding: Query embedding vector\n            doc_embeddings: Document embedding matrix (shape: [n_docs, embedding_dim])\n            relevance_scores: Pre-computed relevance scores (optional)\n            k: Number of results to return\n            lambda_param: Override default lambda (optional)\n            \n        Returns:\n            List of document indices in MMR order\n        \"\"\"\n        if lambda_param is None:\n            lambda_param = self.lambda_param\n        \n        n_docs = len(doc_embeddings)\n        k = min(k, n_docs)\n        \n        # Compute relevance scores if not provided (cosine similarity with query)\n        if relevance_scores is None:\n            query_norm = query_embedding / np.linalg.norm(query_embedding)\n            doc_norms = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)\n            relevance_scores = np.dot(doc_norms, query_norm)\n        \n        # Normalize relevance scores to [0, 1]\n        if relevance_scores.max() > relevance_scores.min():\n            relevance_scores = (relevance_scores - relevance_scores.min()) / (\n                relevance_scores.max() - relevance_scores.min()\n            )\n        \n        # Compute pairwise similarities between documents\n        doc_norms = doc_embeddings / np.linalg.norm(doc_embeddings, axis=1, keepdims=True)\n        doc_similarities = np.dot(doc_norms, doc_norms.T)\n        \n        # MMR selection\n        selected_indices = []\n        remaining_indices = list(range(n_docs))\n        \n        # Select first document (highest relevance)\n        first_idx = np.argmax(relevance_scores)\n        selected_indices.append(first_idx)\n        remaining_indices.remove(first_idx)\n        \n        # Iteratively select documents\n        for _ in range(k - 1):\n            if not remaining_indices:\n                break\n            \n            mmr_scores = []\n            for idx in remaining_indices:\n                # Relevance component\n                relevance = relevance_scores[idx]\n                \n                # Diversity component (max similarity to already selected docs)\n                max_similarity = max(doc_similarities[idx, sel_idx] for sel_idx in selected_indices)\n                \n                # MMR score\n                mmr_score = lambda_param * relevance - (1 - lambda_param) * max_similarity\n                mmr_scores.append(mmr_score)\n            \n            # Select document with highest MMR score\n            best_idx = remaining_indices[np.argmax(mmr_scores)]\n            selected_indices.append(best_idx)\n            remaining_indices.remove(best_idx)\n        \n        return selected_indices\n    \n    def rerank(\n        self,\n        query_embedding: np.ndarray,\n        doc_embeddings: np.ndarray,\n        initial_ranking: List[int],\n        relevance_scores: np.ndarray = None,\n        k: int = 10,\n        lambda_param: float = None\n    ) -> List[int]:\n        \"\"\"\n        Re-rank an initial ranking using MMR for diversity.\n        \n        Args:\n            query_embedding: Query embedding\n            doc_embeddings: Document embeddings\n            initial_ranking: Initial ranking (list of document indices)\n            relevance_scores: Pre-computed relevance scores\n            k: Number of results to return\n            lambda_param: Override default lambda\n            \n        Returns:\n            Re-ranked list of document indices\n        \"\"\"\n        # Only apply MMR to top documents from initial ranking\n        candidate_indices = initial_ranking[:min(len(initial_ranking), k * 3)]\n        candidate_embeddings = doc_embeddings[candidate_indices]\n        \n        if relevance_scores is not None:\n            candidate_scores = relevance_scores[candidate_indices]\n        else:\n            candidate_scores = None\n        \n        # Apply MMR\n        mmr_indices = self.compute_mmr(\n            query_embedding,\n            candidate_embeddings,\n            candidate_scores,\n            k,\n            lambda_param\n        )\n        \n        # Map back to original indices\n        reranked_indices = [candidate_indices[i] for i in mmr_indices]\n        \n        return reranked_indices\n\n\nprint(\"✓ MMRRanker class defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class FAISSIndex:\n    \"\"\"\n    FAISS (Facebook AI Similarity Search) for efficient nearest neighbor search.\n    Enables fast similarity search at scale using approximate methods.\n    \"\"\"\n    \n    def __init__(self, embedding_dim: int = 384):\n        \"\"\"\n        Initialize FAISS index.\n        \n        Args:\n            embedding_dim: Dimension of embeddings (default: 384 for MiniLM)\n        \"\"\"\n        self.embedding_dim = embedding_dim\n        self.index = None\n        self.is_trained = False\n        \n        if faiss is not None:\n            # Use IndexFlatIP (Inner Product) for cosine similarity with normalized vectors\n            self.index = faiss.IndexFlatIP(embedding_dim)\n            print(f\"✓ FAISS index initialized (dim={embedding_dim})\")\n        else:\n            print(\"⚠ FAISS not available - will use brute force search\")\n    \n    def add_embeddings(self, embeddings: np.ndarray):\n        \"\"\"\n        Add embeddings to the FAISS index.\n        \n        Args:\n            embeddings: Array of embeddings to index (shape: [n, embedding_dim])\n        \"\"\"\n        if self.index is not None and faiss is not None:\n            # Normalize embeddings for cosine similarity\n            embeddings = embeddings.astype('float32')\n            faiss.normalize_L2(embeddings)\n            \n            self.index.add(embeddings)\n            self.is_trained = True\n            print(f\"✓ Added {embeddings.shape[0]} embeddings to FAISS index\")\n        else:\n            self.embeddings_fallback = embeddings\n            print(f\"⚠ Using fallback storage for {len(embeddings)} embeddings\")\n    \n    def search(self, query_embedding: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Search for k nearest neighbors.\n        \n        Args:\n            query_embedding: Query embedding vector\n            k: Number of nearest neighbors to return\n            \n        Returns:\n            Tuple of (distances, indices) arrays\n        \"\"\"\n        if self.index is not None and self.is_trained and faiss is not None:\n            # Normalize query\n            query = query_embedding.reshape(1, -1).astype('float32')\n            faiss.normalize_L2(query)\n            \n            # Search\n            distances, indices = self.index.search(query, k)\n            return distances[0], indices[0]\n        else:\n            # Fallback: brute force cosine similarity\n            query_norm = query_embedding / np.linalg.norm(query_embedding)\n            embeddings_norm = self.embeddings_fallback / np.linalg.norm(\n                self.embeddings_fallback, axis=1, keepdims=True\n            )\n            \n            similarities = np.dot(embeddings_norm, query_norm)\n            top_k_indices = np.argsort(similarities)[::-1][:k]\n            top_k_distances = similarities[top_k_indices]\n            \n            return top_k_distances, top_k_indices\n    \n    def batch_search(self, query_embeddings: np.ndarray, k: int = 10) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Search for k nearest neighbors for multiple queries.\n        \n        Args:\n            query_embeddings: Array of query embeddings (shape: [n_queries, embedding_dim])\n            k: Number of nearest neighbors per query\n            \n        Returns:\n            Tuple of (distances, indices) arrays\n        \"\"\"\n        if self.index is not None and self.is_trained and faiss is not None:\n            queries = query_embeddings.astype('float32')\n            faiss.normalize_L2(queries)\n            \n            distances, indices = self.index.search(queries, k)\n            return distances, indices\n        else:\n            # Fallback: batch brute force search\n            distances_list = []\n            indices_list = []\n            for query_emb in query_embeddings:\n                dist, idx = self.search(query_emb, k)\n                distances_list.append(dist)\n                indices_list.append(idx)\n            \n            return np.array(distances_list), np.array(indices_list)\n\n\nprint(\"✓ FAISSIndex class defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class SemanticEmbedder:\n    \"\"\"\n    Sentence-BERT semantic embeddings for capturing meaning and context.\n    Converts text into dense vector representations for similarity computation.\n    \"\"\"\n    \n    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n        \"\"\"\n        Initialize Sentence-BERT model.\n        \n        Args:\n            model_name: Pre-trained model to use (default: all-MiniLM-L6-v2)\n                       Options: 'all-MiniLM-L6-v2' (fast, good quality)\n                               'all-mpnet-base-v2' (best quality, slower)\n        \"\"\"\n        self.model = None\n        self.model_name = model_name\n        self.embeddings = None\n        \n        if SentenceTransformer is not None:\n            try:\n                self.model = SentenceTransformer(model_name)\n                print(f\"✓ Sentence-BERT model '{model_name}' loaded\")\n            except Exception as e:\n                print(f\"⚠ Could not load Sentence-BERT model: {e}\")\n        else:\n            print(\"⚠ Sentence-BERT not available - semantic search disabled\")\n    \n    def encode(self, texts: List[str], show_progress: bool = False) -> np.ndarray:\n        \"\"\"\n        Encode texts into semantic embeddings.\n        \n        Args:\n            texts: List of text strings to encode\n            show_progress: Show progress bar during encoding\n            \n        Returns:\n            Array of embeddings (shape: [n_texts, embedding_dim])\n        \"\"\"\n        if self.model is not None:\n            embeddings = self.model.encode(\n                texts, \n                show_progress_bar=show_progress,\n                convert_to_numpy=True\n            )\n            return embeddings\n        else:\n            # Fallback: return zero vectors\n            return np.zeros((len(texts), 384))\n    \n    def build_index(self, documents: List[str], show_progress: bool = True):\n        \"\"\"\n        Build embeddings index for a document collection.\n        \n        Args:\n            documents: List of documents to index\n            show_progress: Show progress during encoding\n        \"\"\"\n        print(f\"Building semantic embeddings for {len(documents)} documents...\")\n        self.embeddings = self.encode(documents, show_progress=show_progress)\n        print(f\"✓ Embeddings built: shape {self.embeddings.shape}\")\n    \n    def similarity(self, query: str, documents: List[str] = None) -> np.ndarray:\n        \"\"\"\n        Compute cosine similarity between query and documents.\n        \n        Args:\n            query: Query string\n            documents: Documents to compare (uses indexed if None)\n            \n        Returns:\n            Array of similarity scores (0-1 range)\n        \"\"\"\n        if self.model is None:\n            return np.zeros(len(documents) if documents else len(self.embeddings))\n        \n        query_embedding = self.encode([query])[0]\n        \n        if documents is not None:\n            doc_embeddings = self.encode(documents)\n        else:\n            doc_embeddings = self.embeddings\n        \n        # Cosine similarity\n        similarities = np.dot(doc_embeddings, query_embedding) / (\n            np.linalg.norm(doc_embeddings, axis=1) * np.linalg.norm(query_embedding)\n        )\n        \n        return similarities\n    \n    def rank(self, query: str, top_k: int = None) -> List[Tuple[int, float]]:\n        \"\"\"\n        Rank documents by semantic similarity to query.\n        \n        Args:\n            query: Search query\n            top_k: Return only top K results\n            \n        Returns:\n            List of (document_index, similarity_score) tuples\n        \"\"\"\n        similarities = self.similarity(query)\n        ranked_indices = np.argsort(similarities)[::-1]\n        \n        if top_k:\n            ranked_indices = ranked_indices[:top_k]\n        \n        return [(idx, similarities[idx]) for idx in ranked_indices]\n\n\nprint(\"✓ SemanticEmbedder class defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class BM25Ranker:\n    \"\"\"\n    BM25 (Best Matching 25) keyword-based ranking.\n    Provides probabilistic ranking based on term frequency and inverse document frequency.\n    \"\"\"\n    \n    def __init__(self, documents: List[str], k1: float = 1.5, b: float = 0.75):\n        \"\"\"\n        Initialize BM25 ranker.\n        \n        Args:\n            documents: List of text documents to index\n            k1: Term frequency saturation parameter (default: 1.5)\n            b: Length normalization parameter (default: 0.75)\n        \"\"\"\n        self.documents = documents\n        self.k1 = k1\n        self.b = b\n        self.bm25 = None\n        \n        if BM25Okapi is not None:\n            # Tokenize documents (simple whitespace tokenization)\n            tokenized_docs = [doc.lower().split() for doc in documents]\n            self.bm25 = BM25Okapi(tokenized_docs, k1=k1, b=b)\n            print(f\"✓ BM25 index built with {len(documents)} documents\")\n        else:\n            print(\"⚠ BM25 not available - using fallback TF-IDF scoring\")\n    \n    def get_scores(self, query: str) -> np.ndarray:\n        \"\"\"\n        Get BM25 scores for a query against all indexed documents.\n        \n        Args:\n            query: Search query string\n            \n        Returns:\n            Array of BM25 scores for each document\n        \"\"\"\n        if self.bm25 is not None:\n            tokenized_query = query.lower().split()\n            scores = self.bm25.get_scores(tokenized_query)\n            return scores\n        else:\n            # Fallback: simple term frequency scoring\n            query_terms = set(query.lower().split())\n            scores = []\n            for doc in self.documents:\n                doc_terms = doc.lower().split()\n                score = sum(1 for term in query_terms if term in doc_terms)\n                scores.append(score)\n            return np.array(scores)\n    \n    def rank(self, query: str, top_k: int = None) -> List[Tuple[int, float]]:\n        \"\"\"\n        Rank documents by relevance to query.\n        \n        Args:\n            query: Search query\n            top_k: Return only top K results (None = all)\n            \n        Returns:\n            List of (document_index, score) tuples, sorted by score descending\n        \"\"\"\n        scores = self.get_scores(query)\n        ranked_indices = np.argsort(scores)[::-1]\n        \n        if top_k:\n            ranked_indices = ranked_indices[:top_k]\n        \n        return [(idx, scores[idx]) for idx in ranked_indices]\n\n\nprint(\"✓ BM25Ranker class defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Information Retrieval Components\n\nThis section implements the core IR methods: BM25, Sentence-BERT, FAISS, and MMR.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment for Google Colab file upload\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# csv_path = list(uploaded.keys())[0]  # Get uploaded filename\n",
    "\n",
    "# For local execution\n",
    "csv_path = \"dataset/dataset empty -open space-.csv\"\n",
    "\n",
    "# Load activities\n",
    "def load_activities(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and preprocess activity dataset\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Clean and convert data types\n",
    "    df['age_min'] = pd.to_numeric(df['age_min'], errors='coerce')\n",
    "    df['age_max'] = pd.to_numeric(df['age_max'], errors='coerce')\n",
    "    df['duration_mins'] = pd.to_numeric(df['duration_mins'], errors='coerce')\n",
    "    \n",
    "    # Parse tags (handle string representation of lists)\n",
    "    df['tags'] = df['tags'].apply(lambda x: [tag.strip() for tag in str(x).split(',')])\n",
    "    \n",
    "    return df\n",
    "\n",
    "activities_df = load_activities(csv_path)\n",
    "\n",
    "print(f\"✓ Loaded {len(activities_df)} activities\")\n",
    "print(f\"\\nSample activities:\")\n",
    "print(activities_df[['title', 'age_min', 'age_max', 'duration_mins', 'tags']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Activity Ranking Model\n",
    "\n",
    "This model ranks activities based on multiple factors:\n",
    "1. **Age Fit Score**: How well the activity age range matches the group\n",
    "2. **Ability Score**: How the activity difficulty aligns with group ability\n",
    "3. **Coverage Score**: What percentage of the group can participate\n",
    "4. **Diversity Score**: Whether activity suits different ability levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityRankingModel:\n",
    "    \"\"\"Model to rank activities for a family group based on age and ability\"\"\"\n",
    "    \n",
    "    def __init__(self, group: FamilyGroup, activities: pd.DataFrame):\n",
    "        self.group = group\n",
    "        self.activities = activities\n",
    "        self.ranked_activities = None\n",
    "    \n",
    "    def calculate_age_fit_score(self, activity_row) -> float:\n",
    "        \"\"\"\n",
    "        Calculate how well activity age range fits the group.\n",
    "        Returns score 0-1 (higher is better)\n",
    "        \"\"\"\n",
    "        group_min, group_max = self.group.get_age_range()\n",
    "        activity_min = activity_row['age_min']\n",
    "        activity_max = activity_row['age_max']\n",
    "        \n",
    "        # Check if activity range overlaps with group range\n",
    "        if activity_max < group_min or activity_min > group_max:\n",
    "            return 0.0  # No overlap\n",
    "        \n",
    "        # Calculate overlap percentage\n",
    "        overlap_min = max(activity_min, group_min)\n",
    "        overlap_max = min(activity_max, group_max)\n",
    "        overlap_size = overlap_max - overlap_min\n",
    "        \n",
    "        group_range = group_max - group_min + 1\n",
    "        activity_range = activity_max - activity_min + 1\n",
    "        \n",
    "        # Score based on how much of the group range is covered\n",
    "        coverage = overlap_size / group_range if group_range > 0 else 1.0\n",
    "        \n",
    "        return min(coverage, 1.0)\n",
    "    \n",
    "    def calculate_member_coverage(self, activity_row) -> float:\n",
    "        \"\"\"\n",
    "        Calculate what percentage of group members can participate.\n",
    "        Returns score 0-1 (1 = all members can participate)\n",
    "        \"\"\"\n",
    "        if not self.group.members:\n",
    "            return 0.0\n",
    "        \n",
    "        activity_min = activity_row['age_min']\n",
    "        activity_max = activity_row['age_max']\n",
    "        \n",
    "        eligible_count = sum(\n",
    "            1 for member in self.group.members \n",
    "            if activity_min <= member.age <= activity_max\n",
    "        )\n",
    "        \n",
    "        return eligible_count / len(self.group.members)\n",
    "    \n",
    "    def estimate_difficulty(self, activity_row) -> float:\n",
    "        \"\"\"\n",
    "        Estimate activity difficulty based on age range and tags.\n",
    "        Returns difficulty score 1-10 (10 = most difficult)\n",
    "        \"\"\"\n",
    "        # Base difficulty on minimum age requirement\n",
    "        age_difficulty = activity_row['age_min'] / 2.0  # Scale to roughly 1-10\n",
    "        \n",
    "        # Adjust based on tags\n",
    "        difficulty_modifiers = {\n",
    "            'exercise': 1.5,\n",
    "            'sports': 2.0,\n",
    "            'coordination': 1.5,\n",
    "            'STEM': 1.5,\n",
    "            'problem solving': 2.0,\n",
    "            'balance': 1.0,\n",
    "            'sensory': -0.5,\n",
    "            'fun': -0.5,\n",
    "        }\n",
    "        \n",
    "        tags = activity_row['tags']\n",
    "        modifier = sum(\n",
    "            difficulty_modifiers.get(tag.strip().lower(), 0) \n",
    "            for tag in tags\n",
    "        )\n",
    "        \n",
    "        difficulty = age_difficulty + modifier\n",
    "        return np.clip(difficulty, 1, 10)\n",
    "    \n",
    "    def calculate_ability_score(self, activity_row) -> float:\n",
    "        \"\"\"\n",
    "        Calculate how well activity difficulty matches group ability.\n",
    "        Returns score 0-1 (higher = better match)\n",
    "        \"\"\"\n",
    "        activity_difficulty = self.estimate_difficulty(activity_row)\n",
    "        group_avg_ability = self.group.get_avg_ability()\n",
    "        \n",
    "        # Score based on how close difficulty is to average ability\n",
    "        # Activities slightly below average ability are preferred (more accessible)\n",
    "        difference = abs(activity_difficulty - (group_avg_ability - 1))\n",
    "        \n",
    "        # Convert difference to score (smaller difference = higher score)\n",
    "        score = 1.0 - (difference / 10.0)\n",
    "        return max(0, score)\n",
    "    \n",
    "    def calculate_diversity_score(self, activity_row) -> float:\n",
    "        \"\"\"\n",
    "        Calculate whether activity can accommodate different ability levels.\n",
    "        Returns score 0-1 (higher = more inclusive)\n",
    "        \"\"\"\n",
    "        activity_age_range = activity_row['age_max'] - activity_row['age_min']\n",
    "        \n",
    "        # Wider age ranges typically accommodate more ability levels\n",
    "        diversity = min(activity_age_range / 10.0, 1.0)\n",
    "        \n",
    "        return diversity\n",
    "    \n",
    "    def calculate_composite_score(self, activity_row, weights: Dict[str, float] = None) -> float:\n",
    "        \"\"\"\n",
    "        Calculate weighted composite score for an activity.\n",
    "        \n",
    "        Args:\n",
    "            activity_row: Activity data\n",
    "            weights: Dictionary of weights for each component score\n",
    "        \n",
    "        Returns:\n",
    "            Composite score 0-100\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'age_fit': 0.30,       # 30% - Age appropriateness is crucial\n",
    "                'coverage': 0.30,      # 30% - How many can participate\n",
    "                'ability': 0.25,       # 25% - Difficulty match\n",
    "                'diversity': 0.15,     # 15% - Inclusivity\n",
    "            }\n",
    "        \n",
    "        scores = {\n",
    "            'age_fit': self.calculate_age_fit_score(activity_row),\n",
    "            'coverage': self.calculate_member_coverage(activity_row),\n",
    "            'ability': self.calculate_ability_score(activity_row),\n",
    "            'diversity': self.calculate_diversity_score(activity_row),\n",
    "        }\n",
    "        \n",
    "        composite = sum(scores[key] * weights[key] for key in weights.keys())\n",
    "        \n",
    "        # Store individual scores in activity row for debugging\n",
    "        for key, value in scores.items():\n",
    "            activity_row[f'score_{key}'] = value\n",
    "        \n",
    "        return composite * 100  # Scale to 0-100\n",
    "    \n",
    "    def rank_activities(self, top_n: int = None, weights: Dict[str, float] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Rank all activities for the group.\n",
    "        \n",
    "        Args:\n",
    "            top_n: Return only top N activities (None = all)\n",
    "            weights: Custom weights for scoring components\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame of ranked activities with scores\n",
    "        \"\"\"\n",
    "        # Calculate composite score for each activity\n",
    "        ranked = self.activities.copy()\n",
    "        ranked['composite_score'] = ranked.apply(\n",
    "            lambda row: self.calculate_composite_score(row, weights), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Sort by score (descending)\n",
    "        ranked = ranked.sort_values('composite_score', ascending=False)\n",
    "        \n",
    "        # Filter out activities with zero score (completely inappropriate)\n",
    "        ranked = ranked[ranked['composite_score'] > 0]\n",
    "        \n",
    "        # Add rank column\n",
    "        ranked['rank'] = range(1, len(ranked) + 1)\n",
    "        \n",
    "        self.ranked_activities = ranked\n",
    "        \n",
    "        if top_n:\n",
    "            return ranked.head(top_n)\n",
    "        return ranked\n",
    "    \n",
    "    def get_recommendations(self, n: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get top N recommended activities with detailed scores.\n",
    "        \"\"\"\n",
    "        if self.ranked_activities is None:\n",
    "            self.rank_activities()\n",
    "        \n",
    "        cols = ['rank', 'title', 'composite_score', 'score_age_fit', \n",
    "                'score_coverage', 'score_ability', 'score_diversity',\n",
    "                'age_min', 'age_max', 'duration_mins', 'tags']\n",
    "        \n",
    "        return self.ranked_activities[cols].head(n)\n",
    "\n",
    "\n",
    "print(\"✓ Activity Ranking Model defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Activity Rankings\n",
    "\n",
    "Apply the model to rank activities for your family group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance\n",
    "model = ActivityRankingModel(sample_group, activities_df)\n",
    "\n",
    "# Rank activities\n",
    "ranked_activities = model.rank_activities()\n",
    "\n",
    "print(f\"✓ Ranked {len(ranked_activities)} suitable activities\")\n",
    "print(f\"\\nTop 15 Recommended Activities for Your Group:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "recommendations = model.get_recommendations(n=15)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "print(recommendations.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization 1: Score Distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Overall score distribution\n",
    "axes[0, 0].hist(ranked_activities['composite_score'], bins=30, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribution of Composite Scores', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Composite Score')\n",
    "axes[0, 0].set_ylabel('Number of Activities')\n",
    "axes[0, 0].axvline(ranked_activities['composite_score'].mean(), color='red', \n",
    "                   linestyle='--', label=f'Mean: {ranked_activities[\"composite_score\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Component scores for top 20 activities\n",
    "top_20 = ranked_activities.head(20)\n",
    "score_cols = ['score_age_fit', 'score_coverage', 'score_ability', 'score_diversity']\n",
    "score_data = top_20[score_cols].values\n",
    "\n",
    "x = np.arange(len(top_20))\n",
    "width = 0.2\n",
    "\n",
    "for i, col in enumerate(score_cols):\n",
    "    label = col.replace('score_', '').replace('_', ' ').title()\n",
    "    axes[0, 1].bar(x + i * width, top_20[col], width, label=label)\n",
    "\n",
    "axes[0, 1].set_title('Component Scores - Top 20 Activities', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Activity Rank')\n",
    "axes[0, 1].set_ylabel('Score (0-1)')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_xticks(x + width * 1.5)\n",
    "axes[0, 1].set_xticklabels(range(1, 21), rotation=0)\n",
    "\n",
    "# Age range coverage\n",
    "top_15 = ranked_activities.head(15)\n",
    "activity_names = [title[:20] + '...' if len(title) > 20 else title for title in top_15['title']]\n",
    "\n",
    "axes[1, 0].barh(activity_names, top_15['composite_score'], color='teal')\n",
    "axes[1, 0].set_title('Top 15 Activities by Score', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Composite Score')\n",
    "axes[1, 0].invert_yaxis()\n",
    "\n",
    "# Member coverage analysis\n",
    "coverage_dist = ranked_activities['score_coverage'].value_counts().sort_index()\n",
    "axes[1, 1].bar(coverage_dist.index, coverage_dist.values, color='coral', edgecolor='black')\n",
    "axes[1, 1].set_title('Member Coverage Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Coverage Score (% of members who can participate)')\n",
    "axes[1, 1].set_ylabel('Number of Activities')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualizations generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Detailed Analysis of Top Activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_activity_details(activity_row):\n",
    "    \"\"\"Print detailed information about an activity\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RANK #{int(activity_row['rank'])}: {activity_row['title'].upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Overall Score: {activity_row['composite_score']:.1f}/100\")\n",
    "    print(f\"\\nComponent Scores:\")\n",
    "    print(f\"  • Age Fit:        {activity_row['score_age_fit']:.2f} (How well ages match)\")\n",
    "    print(f\"  • Coverage:       {activity_row['score_coverage']:.2f} (% of members who can participate)\")\n",
    "    print(f\"  • Ability Match:  {activity_row['score_ability']:.2f} (Difficulty appropriateness)\")\n",
    "    print(f\"  • Diversity:      {activity_row['score_diversity']:.2f} (Inclusivity)\")\n",
    "    print(f\"\\nActivity Details:\")\n",
    "    print(f\"  • Age Range:      {int(activity_row['age_min'])}-{int(activity_row['age_max'])} years\")\n",
    "    print(f\"  • Duration:       {int(activity_row['duration_mins'])} minutes\")\n",
    "    print(f\"  • Tags:           {', '.join(activity_row['tags'])}\")\n",
    "    print(f\"  • Cost:           {activity_row['cost']}\")\n",
    "    print(f\"  • Location:       {activity_row['indoor_outdoor']}\")\n",
    "    print(f\"  • Players:        {activity_row['players']}\")\n",
    "\n",
    "# Show detailed analysis of top 5\n",
    "print(\"\\n\" + \"#\" * 80)\n",
    "print(\"# DETAILED ANALYSIS - TOP 5 RECOMMENDED ACTIVITIES\")\n",
    "print(\"#\" * 80)\n",
    "\n",
    "for idx in range(min(5, len(ranked_activities))):\n",
    "    print_activity_details(ranked_activities.iloc[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Customize Scoring Weights\n",
    "\n",
    "You can adjust the importance of different factors by changing weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Prioritize activities where ALL members can participate\n",
    "custom_weights = {\n",
    "    'age_fit': 0.20,       # 20%\n",
    "    'coverage': 0.50,      # 50% - Prioritize full group participation\n",
    "    'ability': 0.20,       # 20%\n",
    "    'diversity': 0.10,     # 10%\n",
    "}\n",
    "\n",
    "# Re-rank with custom weights\n",
    "custom_ranked = model.rank_activities(weights=custom_weights)\n",
    "custom_recs = custom_ranked[['rank', 'title', 'composite_score', 'score_coverage', \n",
    "                              'age_min', 'age_max']].head(10)\n",
    "\n",
    "print(\"Top 10 Activities with Custom Weights (Prioritizing Full Participation):\")\n",
    "print(\"=\" * 80)\n",
    "print(custom_recs.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export top recommendations to CSV\n",
    "output_file = 'top_activity_recommendations.csv'\n",
    "recommendations_export = ranked_activities.head(50)[[\n",
    "    'rank', 'title', 'composite_score', 'score_age_fit', 'score_coverage',\n",
    "    'score_ability', 'score_diversity', 'age_min', 'age_max', \n",
    "    'duration_mins', 'cost', 'indoor_outdoor', 'tags'\n",
    "]]\n",
    "\n",
    "recommendations_export.to_csv(output_file, index=False)\n",
    "print(f\"✓ Exported top 50 recommendations to '{output_file}'\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total activities evaluated:     {len(activities_df)}\")\n",
    "print(f\"Suitable activities found:      {len(ranked_activities)}\")\n",
    "print(f\"Average composite score:        {ranked_activities['composite_score'].mean():.2f}\")\n",
    "print(f\"Best activity:                  {ranked_activities.iloc[0]['title']}\")\n",
    "print(f\"Best activity score:            {ranked_activities.iloc[0]['composite_score']:.2f}/100\")\n",
    "print(f\"\\nGroup Details:\")\n",
    "print(f\"  Members:                      {len(sample_group.members)}\")\n",
    "print(f\"  Age range:                    {sample_group.get_age_range()[0]}-{sample_group.get_age_range()[1]} years\")\n",
    "print(f\"  Average ability:              {sample_group.get_avg_ability():.2f}/10\")\n",
    "print(f\"={'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Create Your Own Family Group\n",
    "\n",
    "Modify the cell below to create your own family group and get personalized recommendations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE YOUR OWN GROUP HERE\n",
    "my_group = FamilyGroup([\n",
    "    # Add your family members here\n",
    "    # GroupMember(\"Name\", age=X, overall_ability=Y),\n",
    "    # overall_ability scale: 1=very low, 5=average, 10=very high\n",
    "])\n",
    "\n",
    "if my_group.members:\n",
    "    # Create model for your group\n",
    "    my_model = ActivityRankingModel(my_group, activities_df)\n",
    "    my_ranked = my_model.rank_activities()\n",
    "    my_recs = my_model.get_recommendations(n=20)\n",
    "    \n",
    "    print(f\"\\n🎯 TOP 20 ACTIVITIES FOR YOUR GROUP:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(my_recs.to_string(index=False))\n",
    "else:\n",
    "    print(\"⚠️ Please add members to my_group to get recommendations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook implements a comprehensive activity ranking model that:\n",
    "\n",
    "1. **Merges** group member ages and ability levels\n",
    "2. **Analyzes** activity suitability across multiple dimensions\n",
    "3. **Ranks** activities using a weighted scoring algorithm\n",
    "4. **Provides** detailed recommendations with explanations\n",
    "\n",
    "### Scoring Components:\n",
    "- **Age Fit**: How well activity age range matches group\n",
    "- **Coverage**: Percentage of members who can participate  \n",
    "- **Ability Match**: How activity difficulty aligns with group power/ability\n",
    "- **Diversity**: Whether activity accommodates different levels\n",
    "\n",
    "### Next Steps:\n",
    "- Customize weights based on your priorities\n",
    "- Add more group members\n",
    "- Filter by indoor/outdoor, cost, or season\n",
    "- Integrate with calendar scheduling\n",
    "\n",
    "**Compatible with Google Colab** - Upload your dataset and run!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "name": "Family Activity Ranking Model"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}